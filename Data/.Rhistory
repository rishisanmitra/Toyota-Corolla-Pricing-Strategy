# Load the Necessary Libraries
library(dplyr)
library(ggplot2)
library(psych)
library(car)
library(caret)
library(Metrics)
# Load the data
housing <- read.csv("WestRoxburyCat.csv")
get.wd()
getwd()
setwd("C:/Users/RINA/Desktop/Projects/Real Estate Investment Regression/Data")
# Load the Necessary Libraries
library(dplyr)
library(ggplot2)
library(psych)
library(car)
library(caret)
library(Metrics)
# Load the data
housing <- read.csv("WestRoxburyCat.csv")
# Removing TAX and CAT.VALUE
housing <- housing %>% select(-TAX, -CAT.VALUE)
# Checking Structure of dataset
str(housing)
# Converting the categorical variable into factor
housing$REMODEL <- as.factor(housing$REMODEL)
# Histogram of the target variable
ggplot(housing, aes(x=TOTAL.VALUE)) +
geom_histogram(bins = 30, fill = "steelblue", color = "white") +
labs(title = "Distribution of Total Property Value",
x = "Total Value", y = "Amount")
# Correlation Matrix and Pair Panels to Explore Relationships
num_vars <- housing %>% select(where(is.numeric))
cor_matrix <- cor(num_vars)
round(cor_matrix, 2)
pairs.panels(num_vars, cex.cor = 2.0)
num_vars
# Load the Necessary Libraries
library(dplyr)
library(ggplot2)
library(psych)
library(car)
library(caret)
library(Metrics)
# Load the data
housing <- read.csv("WestRoxburyCat.csv")
# Removing TAX and CAT.VALUE
housing <- housing %>% select(-TAX, -CAT.VALUE)
# Checking Structure of dataset
str(housing)
# Converting the categorical variable into factor
housing$REMODEL <- as.factor(housing$REMODEL)
# Histogram of the target variable
ggplot(housing, aes(x=TOTAL.VALUE)) +
geom_histogram(bins = 30, fill = "steelblue", color = "white") +
labs(title = "Distribution of Total Property Value",
x = "Total Value", y = "Amount")
# Correlation Matrix and Pair Panels to Explore Relationships
num_vars <- housing %>% select(where(is.numeric))
cor_matrix <- cor(num_vars)
round(cor_matrix, 2)
pairs.panels(num_vars, cex.cor = 2.0)
# VIF check for multicollinearity
vif(lm(TOTAL.VALUE~., data = housing))
vif(lm(TOTAL.VALUE ~ . -GROSS.AREA, data = housing))
# Train and Test Data Split
set.seed(1998)
train_index <- createDataPartition(housing$TOTAL.VALUE, p = 0.7, list = FALSE)
train <- housing[train_index, ]
test <- housing[-train_index, ]
model <- lm(TOTAL.VALUE ~ . -GROSS.AREA, data = train)
summary(model)
test$pred_TV <- predict(model, newdata = test)
summary(test$TOTAL.VALUE)
summary(test$pred_TV)
cor(test$TOTAL.VALUE, test$pred_TV)
rmse(test$TOTAL.VALUE, test$pred_TV)
mae(test$TOTAL.VALUE, test$pred_TV)
library(rpart)
library(rattle)
tree_model <- rpart(TOTAL.VALUE ~ . -GROSS.AREA, data = train)
# Plot Tree
fancyRpartPlot(tree_model, tweak = 1.3)
test$pred_tree <- predict(tree_model, newdata = test)
rmse(test$TOTAL.VALUE, test$pred_tree)
mae(test$TOTAL.VALUE, test$pred_tree)
# Load libraries
library(dplyr)
library(caret)
library(fastDummies)
library(neuralnet)
# Load data
used_cars <- read.csv("ToyotaCorolla.csv")
setwd()
getwd()
dir
dir()
lm()
setwd("C:/Users/RINA/Desktop/Projects")
getwd()
list.dirs()
getwd()
setwd("C:/Users/RINA/Desktop/Projects/Automobile Pricing CNN and Regression/Data")
toyota <- used_cars[1:1000, c("Price","Age_08_04","KM","Fuel_Type","HP",
"Met_Color","Automatic","Doors",
"Quarterly_Tax","Weight")]
# Load data
used_cars <- read.csv("ToyotaCorolla.csv")
toyota <- used_cars[1:1000, c("Price","Age_08_04","KM","Fuel_Type","HP",
"Met_Color","Automatic","Doors",
"Quarterly_Tax","Weight")]
# Create binary target
avg_price <- mean(toyota$Price)
toyota$CAT.Price <- ifelse(toyota$Price > avg_price, 1, 0)
toyota <- toyota %>% select(-Price)
# Convert categorical to factors
toyota$Fuel_Type <- as.factor(toyota$Fuel_Type)
toyota$Met_Color <- as.factor(toyota$Met_Color)
toyota$Automatic <- as.factor(toyota$Automatic)
toyota$Doors <- as.factor(toyota$Doors)
# Train-test split
set.seed(1998)
trainIndex <- createDataPartition(toyota$CAT.Price, p = 0.7, list = FALSE)
trainData <- toyota[trainIndex, ]
testData  <- toyota[-trainIndex, ]
# GLM
glm_model <- glm(CAT.Price ~ ., data = trainData, family = binomial)
glm_prob <- predict(glm_model, newdata = testData, type = "response")
testData$glm_class <- ifelse(glm_prob >= 0.5, 1, 0)
conf_mat_glm <- confusionMatrix(as.factor(testData$glm_class),
as.factor(testData$CAT.Price))
conf_mat_glm
# Create dummy variables
nn_train <- dummy_cols(trainData, remove_selected_columns = TRUE)
nn_test  <- dummy_cols(testData,  remove_selected_columns = TRUE)
# Columns to scale (continuous numeric only)
num_vars <- c("Age_08_04","KM","HP","Quarterly_Tax","Weight")
# Scale using training data mean & sd
train_mean <- sapply(nn_train[, num_vars], mean)
train_sd   <- sapply(nn_train[, num_vars], sd)
nn_train[, num_vars] <- scale(nn_train[, num_vars], center = train_mean, scale = train_sd)
nn_test[, num_vars]  <- scale(nn_test[, num_vars], center = train_mean, scale = train_sd)
# Train NN
nn_model <- neuralnet(CAT.Price ~ ., data = nn_train, hidden = c(5,2), linear.output = FALSE)
# Create dummy variables
nn_train <- dummy_cols(trainData, remove_selected_columns = TRUE, remove_first_dummy = TRUE)
nn_test  <- dummy_cols(testData,  remove_selected_columns = TRUE, remove_first_dummy = TRUE)
# Columns to scale (continuous numeric only)
num_vars <- c("Age_08_04","KM","HP","Quarterly_Tax","Weight")
# Scale using training data mean & sd
train_mean <- sapply(nn_train[, num_vars], mean)
train_sd   <- sapply(nn_train[, num_vars], sd)
nn_train[, num_vars] <- scale(nn_train[, num_vars], center = train_mean, scale = train_sd)
nn_test[, num_vars]  <- scale(nn_test[, num_vars], center = train_mean, scale = train_sd)
# Train NN
nn_model <- neuralnet(CAT.Price ~ ., data = nn_train, hidden = c(5,2), linear.output = FALSE)
# Predict NN
nn_pred <- compute(nn_model, nn_test[, -which(names(nn_test) == "CAT.Price")])
nn_prob <- nn_pred$net.result
nn_test$nn_class <- ifelse(nn_prob >= 0.5, 1, 0)
conf_mat_nn <- confusionMatrix(as.factor(nn_test$nn_class),
as.factor(nn_test$CAT.Price))
conf_mat_nn
# Plot NN model
plot(nn_model)
# Load libraries
library(dplyr)
library(caret)
library(fastDummies)
library(neuralnet)
# Load data
used_cars <- read.csv("ToyotaCorolla.csv")
toyota <- used_cars[1:1000, c("Price","Age_08_04","KM","Fuel_Type","HP",
"Met_Color","Automatic","Doors",
"Quarterly_Tax","Weight")]
# Create binary target
avg_price <- mean(toyota$Price)
toyota$CAT.Price <- ifelse(toyota$Price > avg_price, 1, 0)
toyota <- toyota %>% select(-Price)
# Convert categorical to factors
toyota$Fuel_Type <- as.factor(toyota$Fuel_Type)
toyota$Met_Color <- as.factor(toyota$Met_Color)
toyota$Automatic <- as.factor(toyota$Automatic)
toyota$Doors <- as.factor(toyota$Doors)
# Train-test split
set.seed(1998)
trainIndex <- createDataPartition(toyota$CAT.Price, p = 0.7, list = FALSE)
trainData <- toyota[trainIndex, ]
testData  <- toyota[-trainIndex, ]
# GLM
glm_model <- glm(CAT.Price ~ ., data = trainData, family = binomial)
glm_prob <- predict(glm_model, newdata = testData, type = "response")
testData$glm_class <- ifelse(glm_prob >= 0.5, 1, 0)
conf_mat_glm <- confusionMatrix(as.factor(testData$glm_class),
as.factor(testData$CAT.Price))
conf_mat_glm
# NEURAL NETWORK
# Create dummy variables
nn_train <- dummy_cols(trainData, remove_selected_columns = TRUE, remove_first_dummy = TRUE)
nn_test  <- dummy_cols(testData,  remove_selected_columns = TRUE, remove_first_dummy = TRUE)
# Columns to scale (continuous numeric only)
num_vars <- c("Age_08_04","KM","HP","Quarterly_Tax","Weight")
# Scale using training data mean & sd
train_mean <- sapply(nn_train[, num_vars], mean)
train_sd   <- sapply(nn_train[, num_vars], sd)
nn_train[, num_vars] <- scale(nn_train[, num_vars], center = train_mean, scale = train_sd)
nn_test[, num_vars]  <- scale(nn_test[, num_vars], center = train_mean, scale = train_sd)
# Train NN
nn_model <- neuralnet(CAT.Price ~ ., data = nn_train, hidden = c(5,2), linear.output = FALSE)
# Predict NN
nn_pred <- compute(nn_model, nn_test[, -which(names(nn_test) == "CAT.Price")])
# Load libraries
library(dplyr)
library(caret)
library(fastDummies)
library(neuralnet)
# Load data
used_cars <- read.csv("ToyotaCorolla.csv")
toyota <- used_cars[1:1000, c("Price","Age_08_04","KM","Fuel_Type","HP",
"Met_Color","Automatic","Doors",
"Quarterly_Tax","Weight")]
# Create binary target
avg_price <- mean(toyota$Price)
toyota$CAT.Price <- ifelse(toyota$Price > avg_price, 1, 0)
toyota <- toyota %>% select(-Price)
# Convert categorical to factors
toyota$Fuel_Type <- as.factor(toyota$Fuel_Type)
toyota$Met_Color <- as.factor(toyota$Met_Color)
toyota$Automatic <- as.factor(toyota$Automatic)
toyota$Doors <- as.factor(toyota$Doors)
# Train-test split
set.seed(1998)
trainIndex <- createDataPartition(toyota$CAT.Price, p = 0.7, list = FALSE)
trainData <- toyota[trainIndex, ]
testData  <- toyota[-trainIndex, ]
# GLM
glm_model <- glm(CAT.Price ~ ., data = trainData, family = binomial)
glm_prob <- predict(glm_model, newdata = testData, type = "response")
testData$glm_class <- ifelse(glm_prob >= 0.5, 1, 0)
conf_mat_glm <- confusionMatrix(as.factor(testData$glm_class),
as.factor(testData$CAT.Price))
conf_mat_glm
# Create dummy variables
nn_train <- dummy_cols(trainData, remove_selected_columns = TRUE, remove_first_dummy = TRUE)
nn_test  <- dummy_cols(testData,  remove_selected_columns = TRUE, remove_first_dummy = TRUE)
# Columns to scale (continuous numeric only)
num_vars <- c("Age_08_04","KM","HP","Quarterly_Tax","Weight")
# Scale using training data mean & sd
train_mean <- sapply(nn_train[, num_vars], mean)
train_sd   <- sapply(nn_train[, num_vars], sd)
nn_train[, num_vars] <- scale(nn_train[, num_vars], center = train_mean, scale = train_sd)
nn_test[, num_vars]  <- scale(nn_test[, num_vars], center = train_mean, scale = train_sd)
# Train NN
nn_model <- neuralnet(CAT.Price ~ ., data = nn_train, hidden = c(5,2), linear.output = FALSE)
# Predict NN
nn_pred <- compute(nn_model, nn_test[, -which(names(nn_test) == "CAT.Price")])
# Train NN
nn_model <- neuralnet(CAT.Price ~ ., data = nn_train, hidden = c(5,2), linear.output = FALSE)
# Predict NN
nn_pred <- compute(nn_model, nn_test[, -which(names(nn_test) == "CAT.Price")])
nn_prob <- nn_pred$net.result
nn_test$nn_class <- ifelse(nn_prob >= 0.5, 1, 0)
conf_mat_nn <- confusionMatrix(as.factor(nn_test$nn_class),
as.factor(nn_test$CAT.Price))
conf_mat_nn
# Plot NN model
plot(nn_model)
